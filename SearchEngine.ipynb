{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40cf01da",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "988bbe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "# from parsivar import Normalizer, Tokenizer, FindStems, POSTagger, FindChunks\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import argparse\n",
    "import timeit\n",
    "from persian_wordcloud.wordcloud import PersianWordCloud, add_stop_words\n",
    "from wordcloud import STOPWORDS as EN_STOPWORDS\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac48d59",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eca1ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list for loading data\n",
    "data = []\n",
    "data1 = []\n",
    "for line in open('data-30.json', 'r', encoding='utf-8'):\n",
    "    row = json.loads(line)\n",
    "    # get body of each news\n",
    "    data.append(row['Body'])\n",
    "    data1.append(row)\n",
    "\n",
    "news = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "678aaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "778ae979",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6008bf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>به گزارش\\r\\nحوزه قرآن و عترت\\r\\nگروه فرهنگی با...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به گزارش\\r\\nگروه بین‌الملل باشگاه خبرنگاران جو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>به گزارش\\r\\nگروه بین‌الملل باشگاه خبرنگاران جو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به گزارش\\r\\n\\r\\nگروه سیاسی باشگاه خبرنگاران جو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>به گزارش خبرنگار\\r\\nحوزه بهداشت و درمان\\r\\n\\r\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body\n",
       "0  به گزارش\\r\\nحوزه قرآن و عترت\\r\\nگروه فرهنگی با...\n",
       "1  به گزارش\\r\\nگروه بین‌الملل باشگاه خبرنگاران جو...\n",
       "2  به گزارش\\r\\nگروه بین‌الملل باشگاه خبرنگاران جو...\n",
       "3  به گزارش\\r\\n\\r\\nگروه سیاسی باشگاه خبرنگاران جو...\n",
       "4  به گزارش خبرنگار\\r\\nحوزه بهداشت و درمان\\r\\n\\r\\..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.DataFrame(news)\n",
    "news.rename(columns={0:'body'} , inplace=True)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39008cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c686ed5",
   "metadata": {},
   "source": [
    "**Fetch word count for each body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21eb3d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>به گزارش\\r\\nحوزه قرآن و عترت\\r\\nگروه فرهنگی با...</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به گزارش\\r\\nگروه بین‌الملل باشگاه خبرنگاران جو...</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>به گزارش\\r\\nگروه بین‌الملل باشگاه خبرنگاران جو...</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>به گزارش\\r\\n\\r\\nگروه سیاسی باشگاه خبرنگاران جو...</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>به گزارش خبرنگار\\r\\nحوزه بهداشت و درمان\\r\\n\\r\\...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  word_count\n",
       "0  به گزارش\\r\\nحوزه قرآن و عترت\\r\\nگروه فرهنگی با...         184\n",
       "1  به گزارش\\r\\nگروه بین‌الملل باشگاه خبرنگاران جو...         345\n",
       "2  به گزارش\\r\\nگروه بین‌الملل باشگاه خبرنگاران جو...         224\n",
       "3  به گزارش\\r\\n\\r\\nگروه سیاسی باشگاه خبرنگاران جو...         708\n",
       "4  به گزارش خبرنگار\\r\\nحوزه بهداشت و درمان\\r\\n\\r\\...         996"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['word_count'] = news['body'].apply(lambda x: len(str(x).split(\" \")))\n",
    "news[['body','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f154f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     30.000000\n",
       "mean     281.333333\n",
       "std      204.296494\n",
       "min       16.000000\n",
       "25%      157.250000\n",
       "50%      222.500000\n",
       "75%      329.000000\n",
       "max      996.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Descriptive statistics of word counts\n",
    "news.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84561c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(news['body'].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df1bfc",
   "metadata": {},
   "source": [
    "## cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59d066c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_USELESS = r'[^\\w]'  # remove useless characters\n",
    "RE_DIGIT = r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\"  # remove digits\n",
    "RE_SPACE = r'\\s+'  # remove space\n",
    "RE_EMAILS = r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "RE_URLS = r'http\\S+'\n",
    "RE_WWW = r'www\\S+'\n",
    "\n",
    "\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    sentence = re.sub(r'[^\\u0621-\\u06ff]', ' ', sentence)\n",
    "    sentence = arToPersianChar(sentence)\n",
    "    sentence = arToPersianNumb(sentence)\n",
    "    sentence = faToEnglishNumb(sentence)\n",
    "    sentence = re.sub(r'[0-9]', ' ', sentence)\n",
    "    sentence = re.sub(RE_WWW, r' ', sentence)\n",
    "    sentence = re.sub(RE_URLS, r' ', sentence)\n",
    "    sentence = re.sub(RE_EMAILS, r' ', sentence)\n",
    "    sentence = re.sub(RE_USELESS, r' ', sentence)\n",
    "    sentence = re.sub(RE_DIGIT, r' ', sentence)\n",
    "    sentence = re.sub(RE_SPACE, r' ', sentence)\n",
    "    sentence = re.sub(r'[a-zA-Z]', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def arToPersianNumb(number):\n",
    "    dic = {\n",
    "        '١': '۱',\n",
    "        '٢': '۲',\n",
    "        '٣': '۳',\n",
    "        '٤': '۴',\n",
    "        '٥': '۵',\n",
    "        '٦': '۶',\n",
    "        '٧': '۷',\n",
    "        '٨': '۸',\n",
    "        '٩': '۹',\n",
    "        '٠': '۰',\n",
    "    }\n",
    "    return multiple_replace(dic, number)\n",
    "\n",
    "\n",
    "def arToPersianChar(userInput):\n",
    "    dic = {\n",
    "        'ك': 'ک',\n",
    "        'دِ': 'د',\n",
    "        'بِ': 'ب',\n",
    "        'زِ': 'ز',\n",
    "        'ذِ': 'ذ',\n",
    "        'شِ': 'ش',\n",
    "        'سِ': 'س',\n",
    "        'ى': 'ی',\n",
    "        'ي': 'ی'\n",
    "    }\n",
    "    return multiple_replace(dic, userInput)\n",
    "\n",
    "\n",
    "def faToEnglishNumb(number):\n",
    "    dic = {\n",
    "        '۰': '0',\n",
    "        '۱': '1',\n",
    "        '۲': '2',\n",
    "        '۳': '3',\n",
    "        '۴': '4',\n",
    "        '۵': '5',\n",
    "        '۶': '6',\n",
    "        '۷': '7',\n",
    "        '۸': '8',\n",
    "        '۹': '9',\n",
    "    }\n",
    "    return multiple_replace(dic, number)\n",
    "\n",
    "\n",
    "def multiple_replace(dic, text):\n",
    "    pattern = \"|\".join(map(re.escape, dic.keys()))\n",
    "    return re.sub(pattern, lambda m: dic[m.group()], str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e74ea3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_all(document):\n",
    "    clean = ''\n",
    "    for sentence in document:\n",
    "        sentence = clean_sentence(sentence)\n",
    "        clean += sentence\n",
    "    return (clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790574fe",
   "metadata": {},
   "source": [
    "## Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81bf8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "read_file = pd.read_excel ('STOPWORDS.xlsx')\n",
    "read_file.to_csv ('STOPWORDS.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7cc2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(pd.read_csv('STOPWORDS.csv',header=None)[0])\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa67247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c62d7d",
   "metadata": {},
   "source": [
    "**finding_all_unique_words_and_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2149b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_all_unique_words_and_freq(words):\n",
    "#     words_unique = []\n",
    "    word_freq = {}\n",
    "#     for word in words:\n",
    "#         if word not in words_unique:\n",
    "#             words_unique.append(word)\n",
    "    for word in words:\n",
    "        word_freq[word] = words.count(word)\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b35b81f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a9d2f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# all the unique words in the file is stored in word_freq_in_doc.\n",
    "import hazm\n",
    "dict_global = {}\n",
    "files_with_index = {}\n",
    "idx = 0\n",
    "news1 = []\n",
    "normalizer = hazm.Normalizer()\n",
    "for review in news['body']:\n",
    "    sentences = normalizer.normalize(clean_all(review))\n",
    "    ##Convert to list from string\n",
    "    itemtokenized = hazm.word_tokenize(sentences)\n",
    "    lem = hazm.Lemmatizer()\n",
    "    itemlemmatized = [lem.lemmatize(word) for word in itemtokenized if not word in stopwords] \n",
    "#     myStem = FindStems()\n",
    "#     itemStemed = []\n",
    "#     temp = []\n",
    "#     for word in itemtokenized:\n",
    "#         temp.append(myStem.convert_to_stem(word))\n",
    "#     itemStemed.append(' '.join(temp))\n",
    "#     print(len(itemlemmatized))\n",
    "    text = \" \".join(itemlemmatized)\n",
    "    news1.append(text)\n",
    "    dict_global.update(finding_all_unique_words_and_freq(itemtokenized))\n",
    "\n",
    "#     fname = review\n",
    "    files_with_index[idx] = os.path.basename(review)\n",
    "    idx = idx + 1\n",
    "    \n",
    "unique_words_all = set(dict_global.keys())\n",
    "len(unique_words_all)\n",
    "# unique_words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c5412e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_words_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d48f70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(unique_words_all)\n",
    "df.rename(columns={0:'word'} , inplace=True)\n",
    "df.to_csv('Words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a537b",
   "metadata": {},
   "source": [
    "## Preprocess finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e93b9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dict_global.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9749e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dict_global.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "303474d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3fc4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_in_doc = dict_global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04f19cb",
   "metadata": {},
   "source": [
    "##  Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12c92bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionary = []\n",
    "for i,doc in enumerate(news1):\n",
    "    Dictionary += doc.split(\" \")\n",
    "# Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f8235",
   "metadata": {},
   "source": [
    "## PostingList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38d68037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1736\n"
     ]
    }
   ],
   "source": [
    "vocab = []\n",
    "postings = {}\n",
    "\n",
    "for i,doc in enumerate(news1):\n",
    "    token_list = doc.split(' ')\n",
    "    for word in token_list:\n",
    "        c = token_list.count(word)\n",
    "        if word not in postings.keys():\n",
    "            dic ={i:c} \n",
    "            postings[word] = dic\n",
    "            \n",
    "        elif i not in postings[word].keys():\n",
    "            a = postings[word]\n",
    "            a[i] = c\n",
    "            \n",
    "print(len(postings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "326f9a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>PostingList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>گزارش</td>\n",
       "      <td>{0: 1, 1: 2, 2: 1, 3: 1, 4: 2, 5: 1, 6: 1, 7: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>حوزه</td>\n",
       "      <td>{0: 1, 4: 5, 6: 1, 14: 1, 21: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قرآن</td>\n",
       "      <td>{0: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عترت</td>\n",
       "      <td>{0: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>گروه</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 4, 5: 1, 6: 1, 7: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>سراوان</td>\n",
       "      <td>{29: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>خاش</td>\n",
       "      <td>{29: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>نیکشهر</td>\n",
       "      <td>{29: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>راسک</td>\n",
       "      <td>{29: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>سرباز</td>\n",
       "      <td>{29: 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1736 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word                                        PostingList\n",
       "0      گزارش  {0: 1, 1: 2, 2: 1, 3: 1, 4: 2, 5: 1, 6: 1, 7: ...\n",
       "1       حوزه                   {0: 1, 4: 5, 6: 1, 14: 1, 21: 1}\n",
       "2       قرآن                                             {0: 1}\n",
       "3       عترت                                             {0: 1}\n",
       "4       گروه  {0: 1, 1: 1, 2: 1, 3: 1, 4: 4, 5: 1, 6: 1, 7: ...\n",
       "...      ...                                                ...\n",
       "1731  سراوان                                            {29: 1}\n",
       "1732     خاش                                            {29: 1}\n",
       "1733  نیکشهر                                            {29: 1}\n",
       "1734    راسک                                            {29: 1}\n",
       "1735   سرباز                                            {29: 1}\n",
       "\n",
       "[1736 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_items = postings.items()\n",
    "data_list = list(data_items)\n",
    "\n",
    "df_postingList = pd.DataFrame(data_list)\n",
    "df_postingList.rename(columns={0:'word'} , inplace=True)\n",
    "df_postingList.rename(columns={1:'PostingList'} , inplace=True)\n",
    "df_postingList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae53651",
   "metadata": {},
   "source": [
    "### saving postingList to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b9e2b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_postingList.to_csv(r'postingList.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b764f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
